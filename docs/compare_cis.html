<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jean Morrison" />

<meta name="date" content="2016-12-28" />

<title>Comparison of confidence intervals in high dimensions</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">rccSims</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Comparison of confidence intervals in high dimensions</h1>
<h4 class="author"><em>Jean Morrison</em></h4>
<h4 class="date"><em>December 28, 2016</em></h4>

</div>


<p><strong>Last updated:</strong> 2018-04-25</p>
<strong>workflowr checks:</strong> <small>(Click a bullet for more information)</small>
<ul>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>R Markdown file:</strong> up-to-date </summary></p>
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Environment:</strong> empty </summary></p>
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Seed:</strong> <code>set.seed(20180425)</code> </summary></p>
<p>The command <code>set.seed(20180425)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Session information:</strong> recorded </summary></p>
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</details>
</li>
<li>
<p><details> <summary> <strong style="color:blue;">✔</strong> <strong>Repository version:</strong> <a href="https://github.com/jean997/rccSims/tree/c33de4309c7c7043a4bdaf73a5eb5f010d3e36f9" target="_blank">c33de43</a> </summary></p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    docs/figure/

Untracked files:
    Untracked:  .Rbuildignore
    Untracked:  R/get_fcr.R
    Untracked:  analysis/biomarker_sims.rmd
    Untracked:  analysis/ci_bib.bib
    Untracked:  analysis/compare_cis_cache/
    Untracked:  analysis/compare_cis_temp.Rmd
    Untracked:  analysis/compare_cis_temp_cache/
    Untracked:  analysis/linreg_sims.rmd
    Untracked:  data/sim.list.new.rda
    Untracked:  walkthroughs/biomarker_sims_cache/
    Untracked:  walkthroughs/biomarker_sims_files/
    Untracked:  walkthroughs/ci_bib_small.bib
    Untracked:  walkthroughs/compare_cis_cache/
    Untracked:  walkthroughs/compare_cis_files/
    Untracked:  walkthroughs/linreg_sims_cache/
    Untracked:  walkthroughs/linreg_sims_files/

Unstaged changes:
    Modified:   NAMESPACE
    Modified:   walkthroughs/ci_bib.bib
    Modified:   walkthroughs/compare_cis.rmd

</code></pre>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes. </details>
</li>
</ul>
<details> <summary> <small><strong>Expand here to see past versions:</strong></small> </summary>
<ul>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
File
</th>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
<th style="text-align:left;">
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/jean997/rccSims/blob/c33de4309c7c7043a4bdaf73a5eb5f010d3e36f9/analysis/compare_cis.rmd" target="_blank">c33de43</a>
</td>
<td style="text-align:left;">
Jean Morrison
</td>
<td style="text-align:left;">
2018-04-25
</td>
<td style="text-align:left;">
wflow_publish(c(“analysis/compare_cis.rmd”, “analysis/index.Rmd”))
</td>
</tr>
</tbody>
</table>
</ul>
<p></details></p>
<hr />
<p>In this document we will compare several different approaches to building confidence intervals in high dimensions using the example in Section 1.5 of “Rank conditional coverage and confidence intervals in high dimensional problems” by Jean Morrison and Noah Simon.</p>
<p>We will start by setting up the problem and generating data. Then we will run each method one at a time for a single scenario. At the end, you will find the code that generates the results shown in the paper exactly.</p>
<div id="generate-data" class="section level2">
<h2>Generate data</h2>
<p>For this exploration we will use setting 2 from section 1.5. We have 1000 parameters generated from a <span class="math inline">\(N(0, 1)\)</span> distribution. Each of our observed statistics <span class="math inline">\(Z_i\)</span> is generated as <span class="math display">\[Z_i \sim N(\theta_i, 1).\]</span> We will rank these statistics based on their absolute value.</p>
<pre class="r"><code>library(ggplot2)
library(rcc)
library(rccSims)
set.seed(1e7)
theta &lt;- rnorm(1000)
Z &lt;- rnorm(n=1000, mean=theta)
j &lt;- order(abs(Z), decreasing=TRUE)
rank &lt;- match(1:1000, j)</code></pre>
</div>
<div id="naive-confidence-intervals" class="section level2">
<h2>Naive confidence intervals</h2>
<p>We construct standard marginal confidence intervals for the parameters associated with each of these estimates. We will use <span class="math inline">\(\alpha=0.1\)</span> to give an expected rate of coverage of 90%.</p>
<pre class="r"><code>ci.naive &lt;- cbind(Z - qnorm(0.95), Z + qnorm(0.95))
#Average coverage
sum(ci.naive[,1] &lt;= theta &amp; ci.naive[,2] &gt;= theta)/1000</code></pre>
<pre><code>[1] 0.894</code></pre>
<p>We can plot these intervals and color them by whether or not they cover their target parameter. Notice that even though the overall coverage rate is close to the nominal level, a lot of the non-covering intervals are constructed for the most extreme statistics.</p>
<pre class="r"><code>rccSims::plot_cis(rank, ci.naive, theta) + ggtitle(&quot;Standard Marginal Intervals&quot;)</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-3-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>Here is the same plot for only the top 20% of statistics. In this plot, points show the value of the true parameter. <img src="figure/compare_cis.rmd/unnamed-chunk-4-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>This is just one data set. To see what the expected coverage rates at each rank are we’ll simulate 100 more data sets:</p>
<pre class="r"><code>z_many &lt;- replicate(n=100, expr={rnorm(n=1000, mean=theta)})
naive.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  j &lt;- order(abs(zz), decreasing=TRUE)
  ci &lt;- cbind(zz - qnorm(0.975), zz + qnorm(0.975))
  covered &lt;- (ci[,1] &lt;= theta &amp; ci[,2] &gt;= theta)[j]
  return(covered)
})</code></pre>
<p>Plotting the average coverage at each rank: <img src="figure/compare_cis.rmd/unnamed-chunk-6-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
</div>
<div id="selection-adjusted-confidence-intervals" class="section level2">
<h2>Selection adjusted confidence intervals</h2>
<p>Now lets look at the intervals from the selection adjusted methods proposed by <span class="citation">Benjamini and Yekutieli (2005)</span>, <span class="citation">Weinstein, Fithian, and Benjamini (2013)</span>, and <span class="citation">Reid, Taylor, and Tibshirani (2014)</span>. These approaches all require us to make a selection before constructing intervals and we will get different intervals if we select a different subset of estimates. For this exploration, we select the top ten percent of estimates based on the absolute value ranking.</p>
<div id="benjamini2005-intervals" class="section level3">
<h3><span class="citation">Benjamini and Yekutieli (2005)</span> Intervals</h3>
<p>Using this selection rule, the <span class="citation">Benjamini and Yekutieli (2005)</span> intervals are equivalent to the <span class="math inline">\(1-\frac{100*0.1}{1000} = 0.99\)</span> coverage marginal intervals:</p>
<pre class="r"><code>Z.sel &lt;- Z[rank &lt;= 100]
theta.sel &lt;- theta[rank &lt;= 100]
ci.by &lt;- cbind(Z.sel - qnorm(0.995) , Z.sel + qnorm(0.995))
sum(ci.by[,1] &lt;= theta.sel &amp; ci.by[,2] &gt;= theta.sel)/100</code></pre>
<pre><code>[1] 0.89</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-8-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>Now averaging coverage of the BY intervals over 100 data sets:</p>
<pre class="r"><code>system.time(by.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  j &lt;- order(abs(zz), decreasing=TRUE)
  ci &lt;- cbind(zz[j][1:100] - qnorm(0.995), zz[j][1:100] + qnorm(0.995))
  covered &lt;- (ci[,1] &lt;= theta[j][1:100] &amp; ci[,2] &gt;= theta[j][1:100])
  return(covered)
}))</code></pre>
<pre><code>   user  system elapsed 
  0.018   0.000   0.017 </code></pre>
<pre class="r"><code>#The average coverage in each simulation is close to the nominal level
summary(colMeans(by.coverage))</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8600  0.9100  0.9300  0.9282  0.9500  0.9800 </code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-10-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>These intervals have reduced coverage for the top ranked estimates even though the average coverage in the selected set is correct.</p>
</div>
<div id="weinstein2013-intervals" class="section level3">
<h3><span class="citation">Weinstein, Fithian, and Benjamini (2013)</span> Intervals</h3>
<p>For the <span class="citation">Weinstein, Fithian, and Benjamini (2013)</span> intervals, we use code that accompanied that paper. This code is included in the <code>rccSims</code> package for convenience. The <code>Shortest.CI</code> function used below is part of this code. These intervals are asymetric and narrower than the <span class="citation">Benjamini and Yekutieli (2005)</span> intervals but still control the average coverage in the selected set.</p>
<pre class="r"><code>#We need to give this method the &quot;cutpoint&quot; or minimum value of Z
ct &lt;- abs(Z[rank==101])
wfb &lt;- lapply(Z, FUN=function(x){
              if(abs(x) &lt; ct) return(c(NA, NA))
              ci &lt;- try(rccSims:::Shortest.CI(x, ct=ct, alpha=0.1), silent=TRUE)
              if(class(ci) == &quot;try-error&quot;) return(c(NA, NA)) #Sometimes WFB code produces errors
              return(ci)
             })
ci.wfb &lt;- matrix(unlist(wfb), byrow=TRUE, nrow=1000)[rank &lt;= 100,]
sum(ci.wfb[,1] &lt;= theta[rank &lt;=100] &amp; ci.wfb[,2]&gt;= theta[rank&lt;=100])/100</code></pre>
<pre><code>[1] 0.93</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-12-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>Most of the non-covering intervals are still for the parameters with the most significnt estimates. This pattern is clear when we look at the average coverage over 100 data sets:</p>
<pre class="r"><code>system.time(wfb.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  j &lt;- order(abs(zz), decreasing=TRUE)
  ct &lt;- abs(zz[j][101])
  wfb &lt;- lapply(zz[j][1:100], FUN=function(x){
              if(abs(x) &lt; ct) return(c(NA, NA))
              ci &lt;- try(rccSims:::Shortest.CI(x, ct=ct, alpha=0.1), silent=TRUE)
              if(class(ci) == &quot;try-error&quot;) return(c(NA, NA)) #Sometimes WFB code produces errors
              return(ci)
             })
  ci &lt;- matrix(unlist(wfb), byrow=TRUE, nrow=100)
  covered &lt;- (ci[,1] &lt;= theta[j][1:100] &amp; ci[,2] &gt;= theta[j][1:100])
  return(covered)
}))</code></pre>
<pre><code>   user  system elapsed 
  4.319   0.008   4.330 </code></pre>
<pre class="r"><code>#The average coverage in each simulation is close to the nominal level
summary(colMeans(wfb.coverage))</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8400  0.8900  0.9100  0.9053  0.9200  0.9600 </code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-14-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
</div>
<div id="reid2014-intervals" class="section level3">
<h3><span class="citation">Reid, Taylor, and Tibshirani (2014)</span> Intervals</h3>
<p>Finally, lets look at the intervals of <span class="citation">Reid, Taylor, and Tibshirani (2014)</span>. These are implemented in the <code>selectiveInference</code> R package</p>
<pre class="r"><code>library(selectiveInference)
M &lt;- manyMeans(y=Z, k=100, alpha=0.1, sigma=1)
ci.rtt &lt;- matrix(nrow=1000, ncol=2)
ci.rtt[M$selected.set, ] &lt;- M$ci
ci.rtt &lt;- ci.rtt[rank &lt;= 100,]
sum(ci.rtt[,1] &lt;= theta[rank &lt;=100] &amp; ci.rtt[,2]&gt;= theta[rank&lt;=100])/100</code></pre>
<pre><code>[1] 0.88</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-16-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>For the most part, these intervals are narrower than the <span class="citation">Weinstein, Fithian, and Benjamini (2013)</span> intervals. Non-covering intervals tend to be concentrated at the two extremes – parameters associated with the most and least significant estimates tend to go uncovered. We can see this by looking at the average over 100 simulations:</p>
<pre class="r"><code>system.time(rtt.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  j &lt;- order(abs(zz), decreasing=TRUE)
  M &lt;- manyMeans(y=zz, k=100, alpha=0.1, sigma=1)
  ci &lt;- matrix(nrow=1000, ncol=2)
  ci[M$selected.set, ] &lt;- M$ci
  ci &lt;- ci[j,][1:100,]
  covered &lt;- (ci[,1] &lt;= theta[j][1:100] &amp; ci[,2] &gt;= theta[j][1:100])
  return(covered)
}))</code></pre>
<pre><code>   user  system elapsed 
  7.990   0.000   7.991 </code></pre>
<pre class="r"><code>#The average coverage in each simulation is close to the nominal level
summary(colMeans(rtt.coverage))</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8400  0.8800  0.9000  0.9017  0.9225  0.9600 </code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-18-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="parametric-bootstrap" class="section level2">
<h2>Parametric Bootstrap</h2>
<p>Now we will construct intervals for the same problem using the parametric bootstrap described in Section 2.3. Since we are ranking based on absolute value, we will use the variation given in Supplementary Algorithm 2. The procedure is implemented in the <code>par_bs_ci</code> function in the <code>rcc</code> package but here we go through the steps explicitly. First we estimate the average bias at each rank by bootstrapping:</p>
<pre class="r"><code>set.seed(13421)
B &lt;- replicate(n = 500, expr = {
    w &lt;- rnorm(n=1000, mean=Z, sd=1)
    k &lt;- order(abs(w), decreasing=TRUE)
    sign(w[k])*(w[k]-Z[k])
})
dim(B)</code></pre>
<pre><code>[1] 1000  500</code></pre>
<p>Next we calculate the 0.05 and 0.95 quantiles of the bias for each rank.</p>
<pre class="r"><code>qs &lt;- apply(B, MARGIN=1, FUN=function(x){quantile(x, probs=c(0.05, 0.95))})</code></pre>
<p>Finally, we construct the intervals by pivoting</p>
<pre class="r"><code>ci.boot &lt;- cbind(Z[j]-qs[2,], Z[j]-qs[1,])
which.neg &lt;- which(Z[j] &lt; 0)
ci.boot[ which.neg , ] &lt;- cbind(Z[j][which.neg] + qs[1,which.neg], Z[j][which.neg]+qs[2,which.neg])
#Get CI&#39;s in the same order as estimates
ci.boot &lt;- ci.boot[rank,]
sum(ci.boot[,1] &lt;= theta &amp; ci.boot[,2] &gt;= theta)/1000</code></pre>
<pre><code>[1] 0.941</code></pre>
<p>For comparison, here is how to get the same intervals using the <code>rcc</code> package.</p>
<pre class="r"><code>set.seed(13421)
ci.boot2 &lt;- rcc::par_bs_ci(beta=Z, n.rep=500)
head(ci.boot2)</code></pre>
<pre><code>         beta se rank   ci.lower  ci.upper debiased.est
1  0.90690069  1  527 -0.8494054 1.9118492    0.5630546
2  0.02609555  1  989 -1.4182257 1.5079924    0.0142163
3 -1.05117530  1  455 -1.9420156 0.8520663   -0.6277091
4 -1.79176154  1  208 -2.5073640 0.2531810   -1.0707158
5 -0.42610396  1  780 -1.6345952 1.1359413   -0.2044789
6  0.51937390  1  729 -0.8277951 1.6480942    0.4228082</code></pre>
<pre class="r"><code>all.equal(ci.boot2$ci.lower, ci.boot[,1])</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>all.equal(ci.boot2$ci.upper, ci.boot[,2])</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>Here are the parametric bootstrap intervals for all ranks: <img src="figure/compare_cis.rmd/unnamed-chunk-23-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /> and for just the top 20% of ranks <img src="figure/compare_cis.rmd/unnamed-chunk-24-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>Looking at the average coverage over 100 data sets we see that the parametric bootstrap intervals are slightly conservative but that the average coverage for each rank is close to the nominal level.</p>
<pre class="r"><code>system.time(boot.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  ci &lt;- rcc::par_bs_ci(beta=zz)[, c(&quot;ci.lower&quot;, &quot;ci.upper&quot;)]
  covered &lt;- (ci[,1] &lt;= theta &amp; ci[,2] &gt;= theta)
  return(covered)
}))</code></pre>
<pre><code>   user  system elapsed 
 34.948   0.196  35.146 </code></pre>
<pre class="r"><code>summary(colMeans(boot.coverage))</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.9180  0.9330  0.9370  0.9377  0.9440  0.9540 </code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-26-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>The difference between the observed average coverage at each rank and the nominal level is a result of using <span class="math inline">\(Z_i\)</span> as an estimate for <span class="math inline">\(\theta_i\)</span> in the bootstrapping step. If we knew <span class="math inline">\(\theta_i\)</span> we could generate the oracle bootstrap intervals which achieve exactly the right coverage at each rank (and are much smaller):</p>
<pre class="r"><code>oracle.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  ci &lt;- rcc::par_bs_ci(beta=zz, theta=theta)[, c(&quot;ci.lower&quot;, &quot;ci.upper&quot;)]
  covered &lt;- (ci[,1] &lt;= theta &amp; ci[,2] &gt;= theta)
  return(covered)
})
summary(colMeans(oracle.coverage))</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8780  0.8918  0.8990  0.8981  0.9040  0.9170 </code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-28-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
</div>
<div id="empirical-bayes-credible-intervals" class="section level2">
<h2>Empirical Bayes Credible Intervals</h2>
<p>There are also empirical Bayes (EB) proposals for estimating praameters in high dimensional settings. Here we will look at the credible intervals generated using the method of <span class="citation">Stephens (2016)</span>, which is implemented in the <code>ashr</code> package. This method assumes that <span class="math inline">\(\theta_i\)</span> are drawn from a unimodal distribution and that <span class="math inline">\(Z_i \sim N(\theta_i, \sigma_i)\)</span> where <span class="math inline">\(\sigma_i\)</span> is known. These assumptions both hold in this case so <code>ashr</code> does well. Unlike the selection adjusted methods, <code>ashr</code> also has an RCC close to the nominal level at every rank.</p>
<pre class="r"><code>library(ashr)
ash.res &lt;- ash(betahat = Z, sebetahat = rep(1, 1000), mixcompdist = &quot;normal&quot;)
ci.ash &lt;- ashci(ash.res, level=0.9, betaindex = 1:1000, trace=FALSE)
sum(ci.ash[,1]&lt;= theta &amp; ci.ash[,2] &gt;= theta)/1000</code></pre>
<pre><code>[1] 0.877</code></pre>
<p>Here are the ashr intervals at all ranks <img src="figure/compare_cis.rmd/unnamed-chunk-30-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /> and for just the parameters with estimates in the top 20% <img src="figure/compare_cis.rmd/unnamed-chunk-31-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<p>We can look at the average coverage of the <code>ashr</code> credible intervals over 100 simulations. It is worth noting that we have conducted the simulations from more of a frequentist point of view — the parameters were fixed at the beginning and in each simulation we simply generate new statistics. From a Bayesian perspective, it would be more appropriate to generate a new parameter vector from the prior each time. This might explain why we get overall slight undercoverage from the <code>ashr</code> intervals in this setting. <code>ashr</code> also takes substantially longer to run than the parametric bootstrap (on a normal laptop, the code below took nearly 7 minutes while the parametric bootstrap took only 30 seconds.) In this example, <code>ashr</code> does a good job controlling the RCC for the top parameters. This is, in part, because the true parameters are sparse. We found in the paper that when the parameters are not sparse, performance is much worse.</p>
<pre class="r"><code>system.time(ash.coverage &lt;- apply(z_many, MARGIN=2, FUN=function(zz){
  j &lt;- order(abs(zz), decreasing = TRUE)
  ash.res &lt;- ash(betahat = zz, sebetahat = rep(1, 1000), mixcompdist = &quot;normal&quot;)
  ci &lt;- ashci(ash.res, level=0.9, betaindex = 1:1000, trace=FALSE)
  covered &lt;- (ci[,1] &lt;= theta &amp; ci[,2] &gt;= theta)[j]
  return(covered)
}))</code></pre>
<pre><code>   user  system elapsed 
404.218   1.424 405.705 </code></pre>
<pre class="r"><code>summary(colMeans(ash.coverage))</code></pre>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.8220  0.8592  0.8740  0.8712  0.8840  0.9120 </code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-33-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
</div>
<div id="generating-simulation-results-in-the-paper" class="section level2">
<h2>Generating simulation results in the paper</h2>
<p>All of the interval construction methods described in the previous section (except for the <span class="citation">Benjamini and Yekutieli (2005)</span> intervals) are included in the <code>example_sim</code> function in the <code>rccSims</code> package. In Section 1.5, we look at four sets of true parameters:</p>
<ol style="list-style-type: decimal">
<li>All the parameters are equal to zero</li>
<li>All the parameters were genreated from a <span class="math inline">\(N(0, 1)\)</span> distribution</li>
<li>900 of the parameters are equal to 0 and 100 are equal to 3</li>
<li>900 of the parameters are equal to 0 and 100 are drawn from a <span class="math inline">\(N(0, 1)\)</span> distribution</li>
</ol>
<p>First we generate the four vectors of parameters</p>
<pre class="r"><code>example_params &lt;- cbind(rep(0, 1000), 
                        rnorm(n=1000), 
                        rep(c(0, 3), c(900, 100)), 
                        c(rep(0, 900), rnorm(100)))
titles &lt;- c(&quot;All Zero&quot;, &quot;All N(0, 1)&quot;, &quot;100 Effects=3&quot;, &quot;100 Effects N(0, 1)&quot;)</code></pre>
<p>This matrix is also included as a builtin data set in the <code>rccSims</code> package. We generate simulation results using the <code>example_sim</code> function. This function just repeatedly executes the steps in the previous sections and records the coverage and width of the intervals.</p>
<pre class="r"><code>set.seed(6587900)
sim.list &lt;- list()
for(i in 1:4){
  sim.list[[i]] &lt;- example_sim(example_params[,i], n=100, use.abs=TRUE)
}</code></pre>
<p>These results are included as a built-in data set to the <code>rccSims</code> package. The <code>plot_coverage</code> and <code>plot_width</code> functions in the <code>rccSims</code> package create plots of the results.</p>
<pre class="r"><code>data(&quot;sim.list&quot;, package=&quot;rccSims&quot;)
covplots &lt;- list()
widthplots &lt;- list()
titles &lt;- c(&quot;All Zero&quot;, &quot;All N(0, 1)&quot;, &quot;100 Effects=3&quot;, &quot;100 Effects N(0, 1)&quot;)
for(i in 1:4){
  lp &lt;- &quot;none&quot;
  covplots[[i]] &lt;- plot_coverage(sim.list[[i]], proportion=0.2,
        cols=c(&quot;black&quot;,  &quot;deeppink3&quot;,  &quot;blue&quot;, &quot;gold4&quot;, &quot;forestgreen&quot;, &quot;purple&quot;),
        simnames=c(&quot;naive&quot;,  &quot;par&quot;,    &quot;oracle&quot;, &quot;ash&quot;, &quot;wfb&quot;, &quot;selInf1&quot;),
        ltys= c(2, 1, 3, 6, 4, 2), span=0.5, main=titles[i], y.range=c(-0.02, 1.02),
        legend.position = lp) + theme(plot.title=element_text(hjust=0.5))
  widthplots[[i]] &lt;- plot_width(sim.list[[i]], proportion=0.2,
        cols=c(&quot;black&quot;,  &quot;deeppink3&quot;,  &quot;blue&quot;, &quot;gold4&quot;, &quot;forestgreen&quot;, &quot;purple&quot;),
        simnames=c(&quot;naive&quot;,  &quot;par&quot;, &quot;oracle&quot;, &quot;ash&quot;, &quot;wfb&quot;, &quot;selInf1&quot;),
        ltys= c(2, 1, 3, 6, 4, 2), span=0.5, main=titles[i],
        legend.position = lp)+ theme(plot.title=element_text(hjust=0.5))
}
legend &lt;- rccSims:::make_sim_legend(legend.names = c(&quot;Marginal&quot;, &quot;Parametric\nBootstrap&quot;, 
                                                 &quot;Oracle&quot;, &quot;ash&quot;, &quot;WFB&quot;, &quot;RTT&quot;), 
              cols=c(&quot;black&quot;,  &quot;deeppink3&quot;,  &quot;blue&quot;, &quot;gold4&quot;, &quot;forestgreen&quot;, &quot;purple&quot;),
              ltys= c(2, 1, 3, 6, 4, 2))</code></pre>
<pre class="r"><code>covplots[[1]]</code></pre>
<pre><code>Warning: Removed 200 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>Warning: Removed 4 rows containing missing values (geom_path).</code></pre>
<pre class="r"><code>widthplots[[1]]</code></pre>
<pre><code>Warning: Removed 200 rows containing missing values (geom_path).</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-37-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /><img src="figure/compare_cis.rmd/unnamed-chunk-37-2.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<pre class="r"><code>covplots[[2]]</code></pre>
<pre><code>Warning: Removed 201 rows containing non-finite values (stat_smooth).</code></pre>
<pre class="r"><code>widthplots[[2]]</code></pre>
<pre><code>Warning: Removed 201 rows containing missing values (geom_path).</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-38-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /><img src="figure/compare_cis.rmd/unnamed-chunk-38-2.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<pre class="r"><code>covplots[[3]]</code></pre>
<pre><code>Warning: Removed 200 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>Warning: Removed 1 rows containing missing values (geom_path).</code></pre>
<pre class="r"><code>widthplots[[3]]</code></pre>
<pre><code>Warning: Removed 208 rows containing missing values (geom_path).</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-39-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /><img src="figure/compare_cis.rmd/unnamed-chunk-39-2.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
<pre class="r"><code>covplots[[4]]</code></pre>
<pre><code>Warning: Removed 200 rows containing non-finite values (stat_smooth).</code></pre>
<pre class="r"><code>widthplots[[4]]</code></pre>
<pre><code>Warning: Removed 201 rows containing missing values (geom_path).</code></pre>
<p><img src="figure/compare_cis.rmd/unnamed-chunk-40-1.png" width="0.5\textwidth" style="display: block; margin: auto;" /><img src="figure/compare_cis.rmd/unnamed-chunk-40-2.png" width="0.5\textwidth" style="display: block; margin: auto;" /></p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 17.10

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] ashr_2.2-7               selectiveInference_1.2.4
 [3] survival_2.41-3          intervals_0.15.1        
 [5] glmnet_2.0-16            foreach_1.4.4           
 [7] Matrix_1.2-11            rccSims_0.1.0           
 [9] rcc_1.0.0                ggplot2_2.2.1           

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.16      compiler_3.4.2    pillar_1.2.1     
 [4] git2r_0.21.0      plyr_1.8.4        workflowr_1.0.1  
 [7] R.methodsS3_1.7.1 R.utils_2.6.0     iterators_1.0.9  
[10] tools_3.4.2       digest_0.6.15     evaluate_0.10.1  
[13] tibble_1.4.2      gtable_0.2.0      lattice_0.20-35  
[16] rlang_0.2.0       parallel_3.4.2    yaml_2.1.18      
[19] stringr_1.3.0     knitr_1.20        tidyselect_0.2.4 
[22] rprojroot_1.3-2   grid_3.4.2        glue_1.2.0       
[25] rmarkdown_1.9     purrr_0.2.4       tidyr_0.8.0      
[28] magrittr_1.5      whisker_0.3-2     splines_3.4.2    
[31] backports_1.1.2   scales_0.5.0      codetools_0.2-15 
[34] htmltools_0.3.6   MASS_7.3-47       assertthat_0.2.0 
[37] colorspace_1.3-2  labeling_0.3      stringi_1.1.7    
[40] pscl_1.5.2        lazyeval_0.2.1    munsell_0.4.3    
[43] doParallel_1.0.11 truncnorm_1.0-8   SQUAREM_2017.10-1
[46] R.oo_1.21.0      </code></pre>
<div id="refs" class="references">
<div id="ref-Benjamini2005">
<p>Benjamini, Yoav, and Daniel Yekutieli. 2005. “False Discovery Rate–Adjusted Multiple Confidence Intervals for Selected Parameters.” <em>Journal of the American Statistical Association</em> 100 (469). Taylor &amp; Francis: 71–81. doi:<a href="https://doi.org/10.1198/016214504000001907">10.1198/016214504000001907</a>.</p>
</div>
<div id="ref-Reid2014">
<p>Reid, Stephen, Jonathon Taylor, and Robert Tibshirani. 2014. “Post selection point and interval estimation of signal sizes in Gaussian samples.” <em>arXiv Preprint arXiv:1405.3340</em>, May. <a href="http://arxiv.org/abs/1405.3340" class="uri">http://arxiv.org/abs/1405.3340</a>.</p>
</div>
<div id="ref-Stephens2016">
<p>Stephens, Matthew. 2016. “False discovery rates: a new deal.” <em>Biostatistics</em>, October. doi:<a href="https://doi.org/kxw041. doi: 10.1093/biostatistics/kxw041">kxw041. doi: 10.1093/biostatistics/kxw041</a>.</p>
</div>
<div id="ref-Weinstein2013">
<p>Weinstein, Asaf, William Fithian, and Yoav Benjamini. 2013. “Selection Adjusted Confidence Intervals With More Power to Determine the Sign.” <em>Journal of the American Statistical Association</em> 108 (501). Taylor &amp; Francis Group: 165–76. doi:<a href="https://doi.org/10.1080/01621459.2012.737740">10.1080/01621459.2012.737740</a>.</p>
</div>
</div>
</div>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<hr>
<p>
  This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a>
  analysis was created with
  <a href="https://github.com/jdblischak/workflowr">workflowr</a> 1.0.1
</p>
<hr>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
