@article{Efron2008,
abstract = {The classic frequentist theory of hypothesis testing developed by Neyman, Pearson and Fisher has a claim to being the twentieth century's most influential piece of applied mathematics. Something new is happening in the twenty-first century: high-throughput devices, such as microarrays, routinely require simultaneous hypothesis tests for thousands of individual cases, not at all what the classical theory had in mind. In these situations empirical Bayes information begins to force itself upon frequentists and Bayesians alike. The two-groups model is a simple Bayesian construction that facilitates empirical Bayes analysis. This article concerns the interplay of Bayesian and frequentist ideas in the two-groups setting, with particular attention focused on Benjamini and Hochberg's False Discovery Rate method. Topics include the choice and meaning of the null hypothesis in large-scale testing situations, power considerations, the limitations of permutation methods, significance testing for groups of cases (such as pathways in microarray studies), correlation effects, multiple confidence intervals and Bayesian competitors to the two-groups model. CR - Copyright {\&}{\#}169; 2008 Institute of Mathematical Statistics},
archivePrefix = {arXiv},
arxivId = {0808.0603},
author = {Efron, Bradley},
doi = {10.2307/27645871},
eprint = {0808.0603},
file = {:home/jean/Documents/0808.0572.pdf:pdf;:home/jean/Documents/euclid.ss.1215441281.pdf:pdf},
isbn = {0883-4237},
issn = {08834237},
journal = {Statistical Science},
keywords = {and phrases},
mendeley-groups = {Debiasing},
number = {1},
pages = {1--22},
title = {{Microarrays, Empirical Bayes and the Two-Groups Model}},
url = {http://www.jstor.org/stable/27645871},
volume = {23},
year = {2008}
}




@article{Stephens2016,
author = {Stephens, Matthew},
doi = {10.1101/038216},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stephens - 2016 - False Discovery Rates ( FDRs ) A new deal.pdf:pdf},
mendeley-groups = {Xin - 10/2016,Debiasing},
pages = {1--12},
title = {{False Discovery Rates ( FDRs ) A new deal}},
year = {2016}
}


@article{Leeb2014,
abstract = {We consider inference post-model-selection in linear regression. In this setting, Berk et al.(2013) recently introduced a class of confidence sets, the so-called PoSI intervals, that cover a certain non-standard quantity of interest with a user-specified minimal coverage probability, irrespective of the model selection procedure that is being used. In this paper, we generalize the PoSI intervals to post-model-selection predictors.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.4605v1},
author = {Bachoc, Francois and Leeb, Hannes and Potscher, Benedict M},
eprint = {arXiv:1412.4605v1},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leeb, Benedikt - 2014 - Valid confidence intervals for post-model-selection predictors.pdf:pdf},
keywords = {confidence intervals,inference post-model-selection,linear regression,non-standard targets,optimal post-model-selection,predictors},
number = {60643},
title = {{Valid confidence intervals for post-model-selection predictors}},
url = {http://arxiv.org/abs/1412.4605},
year = {2014}
}
@article{Benjamini2005,
abstract = {Often in applied research, confidence intervals (CIs) are constructed or reported only for parameters selected after viewing the data. We show that such selected intervals fail to provide the assumed coverage probability. By generalizing the false discover), rate (FDR) approach from multiple testing to selected multiple CIs, we suggest the false coverage-statement rate (FCR) as a measure of interval coverage following selection. A general procedure is then introduced, offering FCR control at level q under any selection rule. The procedure constructs a marginal CI for each selected parameter, but instead of the confidence level 1 - q being used marginally, q is divided by the number of parameters considered and multiplied by the number selected. If we further use the FDR controlling testing procedure of Benjamini and Hochberg for selecting the parameters, the newly suggested procedure offers CIs that are dual to the testing procedure and are shown to be optimal in the independent case. Under the positive regression dependency condition of Benjamini and Yekutieli, the FCR is controlled for one-sided tests and CIs, as well as for a modification for two-sided testing. Results for general dependency are also given. Finally, using the equivalence of the CIs to testing, we prove that the procedure of Benjamini and Hochberg offers directional FDR control as conjectured.},
author = {Benjamini, Yoav and Yekutieli, Daniel},
doi = {10.1198/016214504000001907},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benjamini, Yekutieli - 2005 - False Discovery Rate–Adjusted Multiple Confidence Intervals for Selected Parameters.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {confidence interval,directional decision,false discovery rate,multiple comparison procedure,positive regression dependency,simultaneous,type iii error},
language = {en},
month = {mar},
number = {469},
pages = {71--81},
publisher = {Taylor {\&} Francis},
title = {{False Discovery Rate–Adjusted Multiple Confidence Intervals for Selected Parameters}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000001907{\#}.VNJctVTN{\_}Qo},
volume = {100},
year = {2005}
}
@article{Berk2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1306.1059v1},
author = {Annals, The},
doi = {10.1214/12-AOS1077},
eprint = {arXiv:1306.1059v1},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berk et al. - 2013 - Valid post-selection inference.pdf:pdf},
issn = {0090-5364},
journal = {Annals of Statistics},
keywords = {Family-wise error,High-dimensional inference,Linear regression,Model selection,Multiple comparison,Sphere packing},
language = {EN},
month = {apr},
number = {2},
pages = {802--837},
publisher = {Institute of Mathematical Statistics},
title = {{Valid post-selection inference}},
url = {http://projecteuclid.org.offcampus.lib.washington.edu/euclid.aos/1369836961},
volume = {41},
year = {2013}
}
@book{Wasserman2006,
abstract = {The book is aimed at master’s-level or Ph.D.-level statistics and computer science students. It is also suitable for researchers in statistics, machine learning and data mining who want to get up to speed quickly on modern nonparametric methods. My goal is to quickly acquaint the reader with the basic concepts in many areas rather than tackling any one topic in great detail. In the interest of covering a wide range of topics, while keeping the book short, I have opted to omit most proofs. Bibliographic remarks point the reader to references that contain further details. Of course, I have had to choose topics to include and to omit, the title notwithstanding. For the most part, I decided to omit topics that are too big to cover in one chapter. For example, I do not cover classification or nonparametric Bayesian inference.},
address = {New York, NY},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Wasserman, Larry},
doi = {10.1007/0-387-30623-4},
editor = {Cassella, George and Fienberg, Stephen and Olkin, Ingram},
eprint = {arXiv:1011.1669v3},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casella, Fienberg, Olkin - 2006 - All of Nonparametric Statistics.pdf:pdf},
isbn = {9780387251455},
issn = {01621459},
keywords = {Density Estimation,Estimating the cdf and,Nonparametric Inference Using Orthogonal Functions,Nonparametric Regression,Normal Means and Minimax Theory,Other Topics,Smoothing: General Concepts,Statistical Functionals,The Bootstrap and the Jackknife,Wavelets and Other Adaptive Methods},
mendeley-groups = {Debiasing},
pages = {272},
pmid = {10911016},
publisher = {Springer},
title = {{All of Nonparametric Statistics}},
year = {2005}
}
@article{Casella2012,
abstract = {The possibility of improving on the usual multivariate normal confidence was first discussed in Stein (1962). Using the ideas of shrinkage, through Bayesian and empirical Bayesian arguments, domination results, both analytic and numerical, have been obtained. Here we trace some of the developments in confidence set estimation.},
archivePrefix = {arXiv},
arxivId = {1203.4935},
author = {Casella, George and Hwang, J. T. Gene},
doi = {10.1214/10-STS319},
eprint = {1203.4935},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casella, Hwang - 2012 - Shrinkage Confidence Procedures.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
month = {feb},
number = {1},
pages = {51--60},
title = {{Shrinkage Confidence Procedures}},
url = {http://arxiv.org/abs/1203.4935},
volume = {27},
year = {2012}
}
@article{Chen2009a,
abstract = {Simulation of genomic sequences under the coalescent with recombination has conventionally been impractical for regions beyond tens of megabases. This work presents an algorithm, implemented as the program MaCS (Markovian Coalescent Simulator), that can efficiently simulate haplotypes under any arbitrary model of population history. We present several metrics comparing the performance of MaCS with other available simulation programs. Practical usage of MaCS is demonstrated through a comparison of measures of linkage disequilibrium between generated program output and real genotype data from populations considered to be structured.},
author = {Chen, Gary K. and Marjoram, Paul and Wall, Jeffrey D.},
doi = {10.1101/gr.083634.108},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Marjoram, Wall - 2009 - Fast and flexible simulation of DNA sequence data(2).pdf:pdf},
isbn = {1088-9051 (Print)
1088-9051 (Linking)},
issn = {10889051},
journal = {Genome Research},
number = {1},
pages = {136--142},
pmid = {19029539},
title = {{Fast and flexible simulation of DNA sequence data}},
volume = {19},
year = {2009}
}
@article{Cheng2013,
abstract = {We used simulations to evaluate methods for assessing statistical significance in association studies. When the statistical model appropriately accounted for relatedness among individuals, unrestricted permutation tests and a few other simulation-based methods effectively controlled type I error rates; otherwise, only gene dropping controlled type I error but at the expense of statistical power.},
author = {Cheng, Riyan and Palmer, Abraham a.},
doi = {10.1534/genetics.112.146332},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng, Palmer - 2013 - A simulation study of permutation, bootstrap, and gene dropping for assessing statistical significance in the cas.pdf:pdf},
issn = {00166731},
journal = {Genetics},
keywords = {Computer Simulation,Genetic Variation,Humans,Models, Genetic,Models, Statistical,Pedigree,Phenotype,Quantitative Trait Loci,Quantitative Trait Loci: genetics},
month = {mar},
number = {3},
pages = {1015--1018},
pmid = {23267053},
title = {{A simulation study of permutation, bootstrap, and gene dropping for assessing statistical significance in the case of unequal relatedness}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3583989{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {193},
year = {2013}
}
@article{Dombroski2010,
abstract = {The accumulation of unfolded or misfolded proteins in the endoplasmic reticulum (ER) results in the condition called "ER stress," which induces the unfolded protein response (UPR), a complex cellular process that includes changes in expression of many genes. Failure to restore homeostasis in the ER is associated with human diseases. To identify the underlying changes in gene expression in response to ER stress, we induced ER stress in human B cells and then measured gene expression at ten time points. We followed up those results by studying cells from 60 unrelated people. We rediscovered genes that were known to play a role in the ER-stress response and uncovered several thousand genes that are not known to be involved. Two of these are VLDLR and INHBE, which showed significant increase in expression after ER stress in B cells and in primary fibroblasts. To study the links between UPR and disease susceptibility, we identified ER-stress-responsive genes that are associated with human diseases and assessed individual differences in the ER-stress response. Many of the UPR genes are associated with Mendelian disorders, such as Wolfram syndrome, and complex diseases, including amyotrophic lateral sclerosis and diabetes. Data from two independent samples showed extensive individual variability in ER-stress response. Additional analyses with monozygotic twins revealed significant correlations within twin pairs in their responses to ER stress, thus showing evidence for heritable variation among individuals. These results have implications for basic understanding of ER function and its role in disease susceptibility. © 2010 The American Society of Human Genetics.},
author = {Dombroski, Beth A. and Nayak, Renuka R. and Ewens, Kathryn G. and Ankener, Wendy and Cheung, Vivian G. and Spielman, Richard S.},
doi = {10.1016/j.ajhg.2010.03.017},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dombroski et al. - 2010 - Gene Expression and Genetic Variation in Response to Endoplasmic Reticulum Stress in Human Cells.pdf:pdf},
isbn = {1537-6605 (Electronic)$\backslash$r0002-9297 (Linking)},
issn = {00029297},
journal = {American Journal of Human Genetics},
keywords = {Animals,Cells, Cultured,Endoplasmic Reticulum,Endoplasmic Reticulum: physiology,Fibroblasts,Fibroblasts: cytology,Fibroblasts: physiology,Gene Expression,Genetic Variation,Homeostasis,Homeostasis: physiology,Humans,Keratinocytes,Keratinocytes: cytology,Keratinocytes: physiology,Male,Receptors, LDL,Receptors, LDL: physiology,Unfolded Protein Response,Unfolded Protein Response: physiology},
month = {may},
number = {5},
pages = {719--729},
pmid = {20398888},
title = {{Gene Expression and Genetic Variation in Response to Endoplasmic Reticulum Stress in Human Cells}},
url = {http://dx.doi.org/10.1016/j.ajhg.2010.03.017},
volume = {86},
year = {2010}
}
@article{Efron,
abstract = {Since Stein's original proposal in 1962, a series of papers have constructed confidence regions of smaller volume than the standard spheres for the mean vector of a multivariate normal distribution. A general approach to this problem is developed here and used to calculate a lower bound on the attainable volume. Bayes and fiducial methods are involved in the calculation. Scheffe-type problems are used to show that low volume by itself does not guarantee favourable inferential properties.},
author = {Efron, Bradley},
doi = {10.1111/j.1467-9868.2006.00560.x},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efron - Unknown - Minimum Volume Confidence Regions for a Multivariate Normal Mean Vector.pdf:pdf},
isbn = {1369-7412},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {fisher-von mises distribution,james-stein estimator,non-central chi,scheffe},
number = {4},
pages = {655--670},
title = {{Minimum volume confidence regions for a multivariate normal mean vector}},
volume = {68},
year = {2006}
}
@article{Efron2011,
abstract = {Journal of the American Statistical Association, Vol.106, No.496, 2011, 1602-1614},
author = {Efron, Bradley},
doi = {10.1198/jasa.2011.tm11181},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efron - 2011 - Tweedie's Formula and Selection Bias.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Bayesian relevance,Empirical Bayes information,F,bayesian relevance,empirical bayes information,false discovery rates,james,regret,s curse,stein,winner},
month = {jan},
number = {496},
pages = {1602--1614},
pmid = {22505788},
title = {{Tweedie’s Formula and Selection Bias}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3325056{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {106},
year = {2011}
}
@article{Efron2012,
abstract = {The parametric bootstrap can be used for the efficient computation of Bayes posterior distributions. Importance sampling formulas take on an easy form relating to the deviance in exponential families, and are particularly simple starting from Jeffreys invariant prior. Because of the i.i.d. nature of bootstrap sampling, familiar formulas describe the computational accuracy of the Bayes estimates. Besides computational methods, the theory provides a connection between Bayesian and frequentist analysis. Efficient algorithms for the frequentist accuracy of Bayesian inferences are developed and demonstrated in a model selection example.},
archivePrefix = {arXiv},
arxivId = {arXiv:1301.2936v1},
author = {Efron, Bradley},
doi = {10.1214/12-AOAS571},
eprint = {arXiv:1301.2936v1},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efron - 2012 - Bayesian inference and the parametric bootstrap.pdf:pdf},
isbn = {1932-6157},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {deviance,exponential families,generalized linear models,jeffreys prior},
month = {oct},
number = {4},
pages = {1971--1997},
pmid = {23843930},
title = {{Bayesian inference and the parametric bootstrap}},
url = {http://projecteuclid.org/euclid.aoas/1356629067},
volume = {6},
year = {2012}
}
@article{Fisher1915,
abstract = {508 Distribution of the Correlation Coeffeients of Samples In the second of these two papers the more difficult problem of the frequency distribution of the correlation coefficient is attempted. For samples of 2 the frequency},
author = {Fisher, R. A.},
doi = {10.2307/2331838},
file = {:home/jean/Desktop/2331838.pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
mendeley-groups = {Debiasing},
number = {4},
pages = {507--521},
title = {{Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population}},
url = {http://biomet.oxfordjournals.org/cgi/reprint/10/4/507.pdf},
volume = {10},
year = {1915}
}

@article{Fithian2014,
abstract = {To perform inference after model selection, we propose controlling the selective type I error; i.e., the error rate of a test given that it was performed. By doing so, we recover long-run frequency properties among selected hypotheses analogous to those that apply in the classical (non-adaptive) context. Our proposal is closely related to data splitting and has a similar intuitive justification, but is more powerful. Exploiting the classical theory of Lehmann and Scheffe (1955), we derive most powerful unbiased selective tests and confidence intervals for inference in exponential family models after arbitrary selection procedures. For linear regression, we derive new selective z-tests that generalize recent proposals for inference after model selection and improve on their power, and new selective t-tests that do not require knowledge of the error variance sigma{\^{}}2.},
archivePrefix = {arXiv},
arxivId = {1410.2597},
author = {Fithian, William and Sun, Dennis and Taylor, Jonathan},
eprint = {1410.2597},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fithian, Sun, Taylor - 2014 - Optimal Inference After Model Selection.pdf:pdf},
month = {oct},
pages = {1--35},
title = {{Optimal Inference After Model Selection}},
url = {http://arxiv.org/abs/1410.2597},
year = {2014}
}
@article{He1992,
author = {He, Kun},
doi = {10.1524/strm.1992.10.12.121},
issn = {2196-7040},
journal = {Statistics {\&} Risk Modeling},
month = {jan},
number = {1-2},
title = {{Parametric Empirical Bayes Confidence Intervals Based on James-Stein Estimator}},
url = {http://www.degruyter.com/view/j/strm.1992.10.issue-1-2/strm.1992.10.12.121/strm.1992.10.12.121.xml},
volume = {10},
year = {1992}
}
@article{Hwang1994,
abstract = {No abstract is available for this item.},
author = {Hwang, J.T.Gene and Ullah, Aman},
doi = {10.1016/0304-4076(94)90041-8},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hwang, Ullah - 1994 - Confidence sets centered at James—Stein estimators.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
number = {1-2},
pages = {145--156},
publisher = {Elsevier},
title = {{Confidence sets centered at James—Stein estimators}},
url = {http://ideas.repec.org/a/eee/econom/v60y1994i1-2p145-156.html},
volume = {60},
year = {1994}
}
@inproceedings{James1961,
abstract = {It has long been customary to measure the adequacy of an estimator by the smallness of its mean squared error. The least squares estimators were studied by Gauss and by other authors later in the nineteenth century. A proof that the best unbiased estimator of a linear function of the means of a set of observed random variables is the least squares estimator was given by Markov [12], a modified version of whose proof is given by David and Neyman [4]. A slightly more general theorem is given by Aitken [1]. Fisher [5] indicated that for large samples the maximum likelihood estimator approximately minimizes the mean squared error when compared with other reasonable estimators. This paper will be concerned with optimum properties or failure of optimum properties of the natural estimator in certain special problems with the risk usually measured by the mean squared error or, in the case of several parameters, by a quadratic function of the estimators. We shall first mention some recent papers on this subject and then give some results, mostly unpublished, in greater detail.},
author = {James, W and Stein, C},
booktitle = {Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability},
issn = {0097-0433},
keywords = {Admissibility,Stein estimation},
language = {EN},
number = {30},
pages = {361--379},
publisher = {The Regents of the University of California},
title = {{Estimation with Quadratic Loss}},
url = {http://books.google.com/books?hl=en{\&}amp;lr={\&}amp;id=tNKkI3QX-UoC{\&}amp;oi=fnd{\&}amp;pg=PA443{\&}amp;dq=Estimation+with+quadratic+loss{\&}amp;ots=4zbGWPFIOr{\&}amp;sig=lKAcUXy7C9471J1MaAbdvR0VoSA},
volume = {1},
year = {1960}
}
@article{Jensen-Seaman2004,
abstract = {Levels of recombination vary among species, among chromosomes within species, and among regions within chromosomes in mammals. This heterogeneity may affect levels of diversity, efficiency of selection, and genome composition, as well as have practical consequences for the genetic mapping of traits. We compared the genetic maps to the genome sequence assemblies of rat, mouse, and human to estimate local recombination rates across these genomes. Humans have greater overall levels of recombination, as well as greater variance. In rat and mouse, the size of the chromosome and proximity to telomere have less effect on local recombination rate than in human. At the chromosome level, rat and mouse X chromosomes have the lowest recombination rates, whereas human chromosome X does not show the same pattern. In all species, local recombination rate is significantly correlated with several sequence variables, including GC{\%}, CpG density, repetitive elements, and the neutral mutation rate, with some pronounced differences between species. Recombination rate in one species is not strongly correlated with the rate in another, when comparing homologous syntenic blocks of the genome. This comparative approach provides additional insight into the causes and consequences of genomic heterogeneity in recombination.},
author = {Jensen-Seaman, M. I.},
doi = {10.1101/gr.1970304},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jensen-Seaman et al. - 2004 - Comparative recombination rates in the rat, mouse, and human genomes.pdf:pdf},
isbn = {1088-9051 (Print)},
issn = {1088-9051},
journal = {Genome Research},
keywords = {Animals,Base Composition,Base Composition: genetics,Chromosomes,Chromosomes: genetics,Crosses, Genetic,Evolution, Molecular,Genetic Variation,Genetic Variation: genetics,Genome,Genome, Human,Humans,Mice,Mice, Inbred Strains,Mice, Obese,Rats,Rats, Inbred BN,Rats, Inbred SHR,Recombination, Genetic,Recombination, Genetic: genetics,Species Specificity},
month = {apr},
number = {4},
pages = {528--538},
pmid = {15059993},
title = {{Comparative Recombination Rates in the Rat, Mouse, and Human Genomes}},
url = {http://www.genome.org/cgi/doi/10.1101/gr.1970304},
volume = {14},
year = {2004}
}
@misc{Benjamini1995,
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
archivePrefix = {arXiv},
arxivId = {0035-9246/95/57289},
author = {Benjamini, Yoav and Hochberg, Yosef},
booktitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
doi = {10.2307/2346101},
eprint = {95/57289},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kasen, Ouellette, Cohen - 1990 - Mainstreaming and postsecondary educational and employment status of a rubella cohort.pdf:pdf},
isbn = {1023072346},
issn = {00359246},
number = {1},
pages = {289 -- 300},
pmid = {2346101},
primaryClass = {0035-9246},
title = {{Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing}},
url = {http://www.jstor.org/stable/2346101},
volume = {57},
year = {1995}
}
@article{Lee2013,
abstract = {We develop a general approach to valid inference after model selection. In a nutshell, our approach produces post-selection inferences with the same frequency guarantees as those given by data splitting but are more powerful. At the core of our framework is a result that characterizes the distribution of a post-selection estimator conditioned on the selection event. We specialize the approach to model selection by the lasso to form valid confidence intervals for the selected coefficients and test whether all relevant variables have been included in the model.},
archivePrefix = {arXiv},
arxivId = {1311.6238},
author = {Lee, Jason D. and Sun, Dennis L. and Sun, Yuekai and Taylor, Jonathan E.},
eprint = {1311.6238},
file = {:home/jean/Desktop/LeeJMP.pdf:pdf},
keywords = {62F03, 62J07, 62E15, lasso, confidence interval, h,and phrases,confidence interval,hypothesis test,lasso,model selection},
pages = {1--32},
title = {{Exact post-selection inference, with application to the lasso}},
url = {http://arxiv.org/abs/1311.6238},
year = {2013}
}
@article{McVean2004,
abstract = {The nature and scale of recombination rate variation are largely unknown for most species. In humans, pedigree analysis has documented variation at the chromosomal level, and sperm studies have identified specific hotspots in which crossing-over events cluster. To address whether this picture is representative of the genome as a whole, we have developed and validated a method for estimating recombination rates from patterns of genetic variation. From extensive single-nucleotide polymorphism surveys in European and African populations, we find evidence for extreme local rate variation spanning four orders in magnitude, in which 50{\%} of all recombination events take place in less than 10{\%} of the sequence. We demonstrate that recombination hotspots are a ubiquitous feature of the human genome, occurring on average every 200 kilobases or less, but recombination occurs preferentially outside genes.},
author = {McVean, G. and Myers, S. and Hunt, S. and Deloukas, P. and Bentley, D. and Donnelly, P.},
doi = {10.1126/science.1092500},
isbn = {1095-9203},
issn = {0036-8075},
journal = {Science},
keywords = {African Continental Ancestry Group,African Continental Ancestry Group: genetics,Base Composition,Bayes Theorem,Chromosome Mapping,Chromosomes, Human, Pair 19,Chromosomes, Human, Pair 19: genetics,Chromosomes, Human, Pair 20,Chromosomes, Human, Pair 20: genetics,Chromosomes, Human, Pair 22,Chromosomes, Human, Pair 22: genetics,Computational Biology,European Continental Ancestry Group,European Continental Ancestry Group: genetics,Female,Genes,Genetic Variation,Genetics, Population,Genome, Human,Humans,Linkage Disequilibrium,Male,Markov Chains,Monte Carlo Method,Pedigree,Polymorphism, Single Nucleotide,Recombination, Genetic,Reproducibility of Results},
month = {apr},
number = {5670},
pages = {581 -- 4},
pmid = {15105499},
title = {{The Fine-Scale Structure of Recombination Rate Variation in the Human Genome}},
url = {http://www.sciencemag.org.offcampus.lib.washington.edu/content/304/5670/581.full?sid=fa7a2de2-c56c-41bc-8384-91cdc24c6abd},
volume = {304},
year = {2004}
}
@article{Montazeri2010,
abstract = {Research on analyzing microarray data has focused on the problem of identifying differentially expressed genes to the neglect of the problem of how to integrate evidence that a gene is differentially expressed with information on the extent of its differential expression. Consequently, researchers currently prioritize genes for further study either on the basis of volcano plots or, more commonly, according to simple estimates of the fold change after filtering the genes with an arbitrary statistical significance threshold. While the subjective and informal nature of the former practice precludes quantification of its reliability, the latter practice is equivalent to using a hard-threshold estimator of the expression ratio that is not known to perform well in terms of mean-squared error, the sum of estimator variance and squared estimator bias. On the basis of two distinct simulation studies and data from different microarray studies, we systematically compared the performance of several estimators representing both current practice and shrinkage. We find that the threshold-based estimators usually perform worse than the maximum-likelihood estimator (MLE) and they often perform far worse as quantified by estimated mean-squared risk. By contrast, the shrinkage estimators tend to perform as well as or better than the MLE and never much worse than the MLE, as expected from what is known about shrinkage. However, a Bayesian measure of performance based on the prior information that few genes are differentially expressed indicates that hard-threshold estimators perform about as well as the local false discovery rate (FDR), the best of the shrinkage estimators studied. Based on the ability of the latter to leverage information across genes, we conclude that the use of the local-FDR estimator of the fold change instead of informal or threshold-based combinations of statistical tests and non-shrinkage estimators can be expected to substantially improve the reliability of gene prioritization at very little risk of doing so less reliably. Since the proposed replacement of post-selection estimates with shrunken estimates applies as well to other types of high-dimensional data, it could also improve the analysis of SNP data from genome-wide association studies.},
author = {Montazeri, Zahra and Yanofsky, Corey M and Bickel, David R},
doi = {10.2202/1544-6115.1504},
isbn = {1544-6115},
issn = {1544-6115},
journal = {Statistical applications in genetics and molecular biology},
keywords = {False Positive Reactions,Gene Expression Profiling,Gene Expression Profiling: statistics {\&} numerical ,Gene Expression Regulation,Likelihood Functions,Models, Statistical,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: statistic,Polymorphism, Single Nucleotide},
month = {jan},
number = {1},
pages = {Article23},
pmid = {20597849},
title = {{Shrinkage estimation of effect sizes as an alternative to hypothesis testing followed by estimation in high-dimensional biology: applications to differential gene expression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20597849},
volume = {9},
year = {2010}
}
@article{Morley2004,
abstract = {Natural variation in gene expression is extensive in humans and other organisms, and variation in the baseline expression level of many genes has a heritable component. To localize the genetic determinants of these quantitative traits (expression phenotypes) in humans, we used microarrays to measure gene expression levels and performed genome-wide linkage analysis for expression levels of 3,554 genes in 14 large families. For approximately 1,000 expression phenotypes, there was significant evidence of linkage to specific chromosomal regions. Both cis- and trans-acting loci regulate variation in the expression levels of genes, although most act in trans. Many gene expression phenotypes are influenced by several genetic determinants. Furthermore, we found hotspots of transcriptional regulation where significant evidence of linkage for several expression phenotypes (up to 31) coincides, and expression levels of many genes that share the same regulatory region are significantly correlated. The combination of microarray techniques for phenotyping and linkage analysis for quantitative traits allows the genetic mapping of determinants that contribute to variation in human gene expression.},
author = {Morley, Michael and Morley, Michael and Molony, Cliona M and Molony, Cliona M and Weber, Teresa M and Weber, Teresa M and Devlin, James L and Devlin, James L and Ewens, Kathryn G and Ewens, Kathryn G and Spielman, Richard S and Spielman, Richard S and Cheung, Vivian G and Cheung, Vivian G},
doi = {10.1038/nature02797},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morley et al. - 2004 - Genetic analysis of genome-wide variation in human gene expression.pdf:pdf},
isbn = {0028-0836},
issn = {1476-4687},
journal = {Nature},
keywords = {Alleles,B-Lymphocytes,B-Lymphocytes: metabolism,Gene Expression Profiling,Gene Expression Regulation,Genetic Variation,Genetic Variation: genetics,Genome, Human,Genomics,Genotype,Humans,Linkage (Genetics),Oligonucleotide Array Sequence Analysis,Phenotype,Polymorphism, Single Nucleotide,Polymorphism, Single Nucleotide: genetics,RNA, Messenger,RNA, Messenger: genetics,RNA, Messenger: metabolism,Transcription, Genetic,Transcription, Genetic: genetics},
month = {aug},
number = {7001},
pages = {743--7},
pmid = {15269782},
title = {{Genetic analysis of genome-wide variation in human gene expression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15269782},
volume = {430},
year = {2004}
}
@article{Qiu2007,
abstract = {Simultaneous inference for a large number, N, of parameters is a challenge. In some situations, such as microarray experiments, researchers are only interested in making inference for the K parameters corresponding to the K most extreme estimates. Hence it seems important to construct simultaneous confidence intervals for these K parameters. The na{\"{\i}}ve simultaneous confidence intervals for the K means (applied directly without taking into account the selection) have low coverage probabilities. We take an empirical Bayes approach (or an approach based on the random effect model) to construct simultaneous confidence intervals with good coverage probabilities. For N = 10,000 and K = 100, typical for microarray data, our confidence intervals could be 77{\%} shorter than the na{\"{\i}}ve K-dimensional simultaneous intervals.},
author = {Qiu, Jing and {Gene Hwang}, J. T.},
doi = {10.1111/j.1541-0420.2007.00770.x},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu, Gene Hwang - 2007 - Sharp simultaneous confidence intervals for the means of selected populations with application to microarray da.pdf:pdf},
issn = {0006341X},
journal = {Biometrics},
keywords = {Bonferroni simultaneous confidence intervals,Differential expression,Empirical Bayes approach,Inference after selection,Random effect models},
month = {sep},
number = {3},
pages = {767--776},
pmid = {17403105},
title = {{Sharp simultaneous confidence intervals for the means of selected populations with application to microarray data analysis}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17403105},
volume = {63},
year = {2007}
}
@article{Reid2014,
abstract = {Recent developments by Lee et al (2013) in post selection inference for the Lasso are adapted to the orthogonal setting whereby sample elements have different underlying signal sizes. We show that other selection procedures, like selecting the {\$}K{\$} largest (absolute) sample elements and the Benjamini-Hochberg procedure, can be cast into their framework, allowing us to leverage their results. Point and interval estimates for signal sizes are proposed. These seem to perform quite well against competitors, both recent and more tenured.},
archivePrefix = {arXiv},
arxivId = {arXiv:1405.3340v3},
author = {Reid, Stephen and Taylor, Jonathon and Tibshirani, Robert},
eprint = {arXiv:1405.3340v3},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reid, Tibshirani - 2014 - Post selection point and interval estimation of signal sizes in Gaussian samples.pdf:pdf},
journal = {arXiv preprint arXiv:1405.3340},
mendeley-groups = {Debiasing},
month = {may},
number = {1},
pages = {1--22},
title = {{Post selection point and interval estimation of signal sizes in Gaussian samples}},
url = {http://arxiv.org/abs/1405.3340},
year = {2014}
}

@article{Samworth2005,
abstract = {Suppose that X has a k-variate spherically symmetric distribution with mean vector $\theta$ and identity covariance matrix. We present two spherical confidence sets for $\theta$, both centred at a positive part Stein estimator {\&}lt;tex-math{\&}gt;{\$}T{\_}s{\^{}}+(X){\$}{\&}lt;/tex-math{\&}gt;. In the first, we obtain the radius by approximating the upper {\&}lt;tex-math{\&}gt;{\$}\backslashalpha-point{\$}{\&}lt;/tex-math{\&}gt; of the sampling distribution of {\&}lt;tex-math{\&}gt;{\$}\backslash|T{\^{}}+{\_}s(X) - \backslashtheta\backslash|{\^{}}2{\$}{\&}lt;/tex-math{\&}gt; by the first two non-zero terms of its Taylor series about the origin. We can analyse some of the properties of this confidence set and see that it performs well in terms of coverage probability, volume and conditional behaviour. In the second method, we find the radius by using a parametric bootstrap procedure. Here, even greater improvement in terms of volume over the usual confidence set is possible, at the expense of having a less explicit radius function. A real data example is provided, and extensions to the unknown covariance matrix and elliptically symmetric cases are discussed.},
author = {Samworth, Richard},
doi = {10.1111/j.1467-9868.2005.00505.x},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Samworth - 2005 - Small confidence sets for the mean of a spherically symmetric distribution.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B. Statistical Methodology},
keywords = {Conditional properties,Confidence sets,Coverage probability,Location parameter,Multivariate normal distribution,Parametric bootstrap,Spherically symmetric distribution,Stein estimator,Volume},
number = {3},
pages = {343--361},
title = {{Small Confidence Sets for the Mean of a Spherically Symmetric Distribution}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed{\&}cmd=Retrieve{\&}dopt=AbstractPlus{\&}list{\_}uids=9021917933691435873related:YXtnfo9KNH0J$\backslash$npapers3://publication/doi/10.2307/3647664},
volume = {67},
year = {2005}
}
@article{Shao1994,
author = {Shao, Peter Yi-Shi and Strawderman, William E.},
doi = {10.1214/aos/1176325640},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {Minimaxity,location parameters,squared error loss},
language = {EN},
month = {sep},
number = {3},
pages = {1517--1538},
publisher = {Institute of Mathematical Statistics},
title = {{Improving on the James-Stein Positive-Part Estimator}},
url = {http://projecteuclid.org/euclid.aos/1176325640},
volume = {22},
year = {1994}
}
@article{Simon2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1311.3709v1},
author = {Simon, Noah and Simon, Richard},
eprint = {arXiv:1311.3709v1},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simon, Simon - 2013 - On Estimating Many Means , Selection Bias , and the Bootstrap.pdf:pdf},
journal = {arXiv preprint arXiv:1311.3709},
keywords = {bootstrap,compound decision theory,empirical bayes,james-stein,mean,regres-,selection bias,shrinkage,sion to the mean},
pages = {1--25},
title = {{On Estimating Many Means, Selection Bias, and the Bootstrap}},
year = {2013}
}
@inproceedings{Stein1956,
abstract = {If one observes the real random variables Xi,...,Xn independently normally distributed with unknown means m1,..., mn and variance 1, it is customary to estimate mi by Xi. If the loss is the sum of squares of the errors, this estimator is admissible for n < 2, but inadmissible for n 3. Since the usual estimator is best among those which transform correctly under translation, any admissible estimator for n 3 involves an arbitrary choice. While the results of this paper are not in a form suitable for immediate practical application, the possible improvement over the usual estimator seems to be large enough to be of practical importance if n is large.},
author = {Stein, C.},
booktitle = {Proceedings of the Third Berkeley symposium on mathematical statistics and probability},
issn = {0097-0433},
keywords = {Information inequality,Shrinkage estimator,Spherically symmetrical estimator,Stein paradox},
language = {EN},
number = {4},
pages = {197--206},
publisher = {The Regents of the University of California},
title = {{Inadmissibility of the usual estimator for the mean of a multivariate normal distribution}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Inadmissibility+of+the+Usual+Estimator+for+the+Mean+of+a+Multivariate+Normal+Distribution{\#}0},
volume = {1},
year = {1955}
}
@article{Sun2005,
abstract = {The accuracy of gene localization, the reliability of locus-specific effect estimates, and the ability to replicate initial claims of linkage and/or association have emerged as major methodological concerns in genomewide studies of complex diseases and quantitative traits. To address the issue of multiple comparisons inherent in genomewide studies, the use of stringent criteria for assessing statistical significance has been generally acknowledged as a strategy to control type I error. However, the application of genomewide significance criteria does not take account of the selection bias introduced into parameter estimates, e.g., estimates of locus-specific effect size of disease/trait loci. Some have argued that reliable locus-specific parameter estimates can only be obtained in an independent sample. In this report, we examine statistical resampling techniques, including cross-validation and the bootstrap, applied to the initial sample to improve the estimation of locus-specific effects. We compare them with the naive method in which all data are used for both hypothesis testing and parameter estimation, as well as with the split-sample approach in which part of the data are reserved for estimation. Upward bias of the naive estimator and inadequacy of the split-sample approach are derived analytically under a simple quantitative trait model. Simulation studies of the resampling methods are performed for both the simple model and a more realistic genomewide linkage analysis. Our results suggest that cross-validation and bootstrap methods can substantially reduce the estimation bias, especially when the effect size is small or there is no genetic effect.},
author = {Sun, Lei and Bull, Shelley B},
doi = {10.1002/gepi.20068},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Bull - 2005 - Reduction of selection bias in genomewide studies by resampling.pdf:pdf},
isbn = {0741-0395},
issn = {0741-0395},
journal = {Genetic epidemiology},
keywords = {Algorithms,Chromosome Mapping,Computer Simulation,Computer Simulation: statistics {\&} numerical data,Genetic Linkage,Genetic Markers,Genome, Human,Humans,Models, Genetic,Sample Size,Selection Bias,Siblings},
month = {may},
number = {4},
pages = {352--67},
pmid = {15761913},
title = {{Reduction of selection bias in genomewide studies by resampling.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15761913},
volume = {28},
year = {2005}
}
@article{Tan2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1405.4251v1},
author = {Tan, Km and Simon, N and Witten, D},
eprint = {arXiv:1405.4251v1},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan, Simon, Witten - 2014 - Selection Bias Correction and Effect Size Estimation under Dependence.pdf:pdf},
journal = {arXiv preprint arXiv:1405.4251},
keywords = {effect size,empirical bayes,frequentist selection bias,high-dimensional data,s curse,test statistics,winner},
pages = {1--22},
title = {{Selection Bias Correction and Effect Size Estimation under Dependence}},
url = {http://arxiv.org/abs/1405.4251},
year = {2014}
}
@article{Taylor2014,
abstract = {In this paper we propose new inference tools for forward stepwise and least angle regression. We first present a general scheme to perform valid inference after any selection event that can be characterized as the observation vector y falling into some polyhedral set. This framework then allows us to derive conditional (post-selection) hypothesis tests at any step of the forward stepwise and least angle regression procedures. We derive an exact null distribution for our proposed test statistics in finite samples, yielding p-values with exact type I error control. The tests can also be inverted to produce confidence intervals for appropriate underlying regression parameters. Application of this framework to general likelihood-based regression models (e.g., generalized linear models and the Cox model) is also discussed.},
archivePrefix = {arXiv},
arxivId = {1401.3889},
author = {Taylor, Jonathan and Lockhart, Richard and Tibshirani, Ryan J. and Tibshirani, Robert},
eprint = {1401.3889},
file = {:home/jean/Desktop/1401.3889v5.pdf:pdf},
keywords = {confidence interval,forward stepwise regression,lasso,least angle regression,p-value,post-},
pages = {1--26},
title = {{Exact Post-selection Inference for Forward Stepwise and Least Angle Regression}},
url = {http://arxiv.org/abs/1401.3889},
year = {2014}
}
@article{Tseng1997,
author = {Tseng, Yu-Ling and Brown, Lawrence D.},
doi = {10.1214/aos/1069362396},
issn = {00905364},
journal = {The Annals of Statistics},
keywords = {Confidence sets,Coverage probability,James-Stein estimator,Multivariate normal mean,Pseudo-empirical-bayes construction,Stein-type estimator,Volume},
month = {oct},
number = {5},
pages = {2228--2258},
publisher = {Institute of Mathematical Statistics},
title = {{Good exact confidence sets for a multivariate normal mean}},
url = {http://projecteuclid.org/euclid.aos/1069362396},
volume = {25},
year = {1997}
}
@article{Weinstein2013,
abstract = {In many current large-scale problems, confidence intervals (CIs) are constructed only for the parameters that are large, as indicated by their estimators, ignoring the smaller parameters. Such selective inference poses a problem to the usual marginal CIs that no longer offer the right level of coverage, not even on the average over the selected parameters. We address this problem by developing three methods to construct short and valid CIs for the location parameter of a symmetric unimodal distribution, while conditioning on its estimator being larger than some constant threshold. In two of these methods, the CI is further required to offer early sign determination, that is, to avoid including parameters of both signs for relatively small values of the estimator. One of the two, the Conditional Quasi-Conventional CI, offers a good balance between length and sign determination while protecting from the effect of selection. The CI is not symmetric, extending more toward 0 than away from it, nor is it of constant shape. However, when the estimator is far away from the threshold, the proposed CI tends to the usual marginal one. In spite of its complexity, it is specified by closed form expressions, up to a small set of constants that are each the solution of a single variable equation.},
author = {Weinstein, Asaf and Fithian, William and Benjamini, Yoav},
doi = {10.1080/01621459.2012.737740},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinstein, Fithian, Benjamini - 2013 - Selection Adjusted Confidence Intervals With More Power to Determine the Sign.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {conditional confidence intervals,false coverage rate,selective inference},
language = {en},
month = {mar},
number = {501},
pages = {165--176},
publisher = {Taylor {\&} Francis Group},
title = {{Selection Adjusted Confidence Intervals With More Power to Determine the Sign}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2012.737740},
volume = {108},
year = {2013}
}
@article{Zhao2012a,
author = {Zhao, Zhigen and {Gene Hwang}, J. T.},
doi = {10.1111/j.1467-9868.2012.01033.x},
file = {:home/jean/Desktop/j.1467-9868.2012.01033.x.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Multiplicity,Simultaneous intervals},
number = {5},
pages = {871--891},
title = {{Empirical Bayes false coverage rate controlling confidence intervals}},
url = {http://doi.wiley.com/10.1111/j.1467-9868.2012.01033.x},
volume = {74},
year = {2012}
}
@article{Zhong2008,
abstract = {Genome-wide association studies (GWAS) provide an important approach to identifying common genetic variants that predispose to human disease. A typical GWAS may genotype hundreds of thousands of single nucleotide polymorphisms (SNPs) located throughout the human genome in a set of cases and controls. Logistic regression is often used to test for association between a SNP genotype and case versus control status, with corresponding odds ratios (ORs) typically reported only for those SNPs meeting selection criteria. However, when these estimates are based on the original data used to detect the variant, the results are affected by a selection bias sometimes referred to the "winner's curse" (Capen and others, 1971). The actual genetic association is typically overestimated. We show that such selection bias may be severe in the sense that the conditional expectation of the standard OR estimator may be quite far away from the underlying parameter. Also standard confidence intervals (CIs) may have far from the desired coverage rate for the selected ORs. We propose and evaluate 3 bias-reduced estimators, and also corresponding weighted estimators that combine corrected and uncorrected estimators, to reduce selection bias. Their corresponding CIs are also proposed. We study the performance of these estimators using simulated data sets and show that they reduce the bias and give CI coverage close to the desired level under various scenarios, even for associations having only small statistical power.},
author = {Zhong, Hua and Prentice, Ross L},
doi = {10.1093/biostatistics/kxn001},
file = {:home/jean/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong, Prentice - 2008 - Bias-reduced estimators and confidence intervals for odds ratios in genome-wide association studies.pdf:pdf},
isbn = {1468-4357 (Electronic)$\backslash$r1465-4644 (Linking)},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {Algorithms,Computer Simulation,Confidence Intervals,Gene Frequency,Genetic Predisposition to Disease,Genetic Predisposition to Disease: genetics,Genome-Wide Association Study,Genome-Wide Association Study: methods,Genotype,Humans,Likelihood Functions,Logistic Models,Models, Statistical,Odds Ratio,Phenotype,Polymorphism, Single Nucleotide,Risk Factors,Selection Bias},
month = {oct},
number = {4},
pages = {621--34},
pmid = {18310059},
title = {{Bias-reduced estimators and confidence intervals for odds ratios in genome-wide association studies.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2536726{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2008}
}
